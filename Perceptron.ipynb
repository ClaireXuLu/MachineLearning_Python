{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  三、感知机\n",
    "\n",
    "分类模型；找到一个超平面$\\vec w \\vec x +b =0$ 大于0进行分类判断；感知机也可以看成一个单层神经网络\n",
    "\n",
    "![image-20221017083227358](https://s2.loli.net/2022/10/20/O5rNWMbes4juUfv.png)\n",
    "\n",
    "## 1. 模型\n",
    "\n",
    "$$\n",
    "z = \\vec w \\cdot \\vec x + b=w_1x_1+w_2x_2+...+w_nx_n+b\\\\\n",
    "y=sign(z)=\n",
    "\\begin{cases}\n",
    "1, z\\geq0\\\\\n",
    "-1, z<0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "## 2. 损失函数\n",
    "\n",
    "$$\n",
    "J(w) = -\\sum_{x_i\\in{M}}{y^{(i)}( \\vec w \\cdot \\vec x^{(i)}+b)}\n",
    "$$\n",
    "\n",
    "其中M为错误分类的样本点集合，$\\vec w ,  \\vec x^{(i)}$ 都是n维的向量，点表示内积运算\n",
    "\n",
    "## 3. 损失函数的原理推导\n",
    "\n",
    "损失函数的几何意义为所有错误分类样本点距离超平面$\\vec x \\vec w + b=0$ 的距离之和，接下来证明两点\n",
    "\n",
    "* $\\vec w$ 为超平面的法向量\n",
    "\n",
    "  假设O为坐标原点，P1， P2为超平面上的任意两点，其坐标分别为为$\\vec x^{(1)}和\\vec x^{(2)}$ ， 因此$\\vec w 和 \\vec{P1P2}$ 的內积为：\n",
    "  $$\n",
    "  \\vec w \\cdot \\overrightarrow {P_1P_2}=\\vec w \\cdot (\\overrightarrow {OP_2} - \\overrightarrow {OP_1})\\\\\n",
    "  =\\vec w (\\vec x^{(1)} - \\vec x^{(2)})\\\\\n",
    "  =-b - (-b)=0\n",
    "  $$\n",
    "  因此得证$\\vec w$ 为超平面的法向量\n",
    "\n",
    "* 误分类点到超平面的距离公式为 $d = -y^{(i)}( \\vec w \\cdot \\vec x^{(i)}+b)$ \n",
    "\n",
    "  设坐标原点为O， 误分类点为P，其在超平面的投影点为P',其坐标分别为为$\\vec x和\\vec x’$ 因为$\\overrightarrow {P'P}$ 和$\\vec w$ 平行，所以其內积的绝对值为两向量的模的乘积\n",
    "  $$\n",
    "  |\\vec w \\cdot \\overrightarrow {P'P}| = ||\\vec w||_2 *d\n",
    "  $$\n",
    "  又因为P'在超平面上， 因此有$\\vec w \\cdot \\vec x' + b = 0$\n",
    "  $$\n",
    "  |\\vec w \\cdot \\overrightarrow {P'P}|=|\\vec w \\cdot (\\overrightarrow{OP} -\\overrightarrow{OP'})|\n",
    "  \\\\=|\\vec w \\cdot (\\vec x-\\vec x')|\n",
    "  \\\\=|\\vec w \\cdot \\vec x + b |\n",
    "  $$\n",
    "  最后，因为对于误分类点必定满足$y^{(i)}( \\vec w \\cdot \\vec x^{(i)}+b) < 0$ ，  因此得误分类点到超平面的距离公式为 $d = -y^{(i)}( \\vec w \\cdot \\vec x^{(i)}+b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. python实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, theta):\n",
    "    return X @ theta\n",
    "\n",
    "\n",
    "def predict(x, theta):\n",
    "    flags = model(x, theta)\n",
    "    y = np.ones_like(flags)\n",
    "    y[np.where(flags < 0)[0]] = -1\n",
    "    return y\n",
    "\n",
    "def computerCost(X, y, theta):\n",
    "    y_pred = predict(X, theta)\n",
    "    error_index = np.where(y_pred != y)[0]\n",
    "    return np.squeeze(-y_pred[error_index].T @ y[error_index])\n",
    "\n",
    "\n",
    "def gradientDescent(X, y, alpha, num_iters=1000):\n",
    "    # m = X.shape[0]\n",
    "    #X = np.hstack((np.ones((m, 1)), X))\n",
    "    #y = y[:, np.newaxis]\n",
    "    n = X.shape[1]\n",
    "    theta = np.zeros((n, 1))\n",
    "    J_history = []\n",
    "    for i in range(num_iters):\n",
    "        y_pred = predict(X, theta)\n",
    "        error_index = np.where(y_pred != y)[0]\n",
    "        theta = theta + alpha * X[error_index, :].T @ y[error_index]\n",
    "        cur_cost = computerCost(X, y, theta)\n",
    "        J_history.append(cur_cost)\n",
    "        print('.', end='')\n",
    "        if cur_cost == 0:\n",
    "            print(f'Finished in advance in iteration {i+1}!')\n",
    "            break\n",
    "        \n",
    "    return theta, J_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一个实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "(150, 5) (150, 1)\n",
      ".......Finished in advance in iteration 7!\n",
      "acc:\n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "print(iris.keys())\n",
    "print(iris.target_names)\n",
    "X = iris.data\n",
    "m = X.shape[0]\n",
    "X = np.hstack((np.ones((m, 1)), X))\n",
    "y = iris.target\n",
    "y[np.where(y!=0)[0]] = -1\n",
    "y[np.where(y==0)[0]] = 1\n",
    "y = y.reshape((len(y), 1))\n",
    "print(X.shape, y.shape)\n",
    "theta, J_history = gradientDescent(X, y, 0.01, 1000)\n",
    "y_pred = predict(X, theta)\n",
    "\n",
    "acc = np.sum(y_pred == y)/len(y)\n",
    "print('acc:\\n', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('myEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e38ba9a5944a3421f77c1c2862354ade0dcdf22eb57eefe299a6ebec0eb6e7ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
