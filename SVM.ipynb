{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 九、SVM支持向量机(Support Vector Machine)\n",
    "\n",
    "## 1. Model\n",
    "\n",
    "其实从预测的模型上来说和感知机是一样的\n",
    "$$\n",
    "z = \\vec w \\cdot \\vec x + b=w_1x_1+w_2x_2+...+w_nx_n+b\\\\\n",
    "y=sign(z)=\n",
    "\\begin{cases}\n",
    "1, z\\geq0\\\\\n",
    "0, z<0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "## 2. 损失函数\n",
    "\n",
    "SVM的损失函数\n",
    "$$\n",
    "J(w) = \\sum_{x_i\\in{M}}{[y^{(i)}*cost_1( \\vec w \\cdot \\vec x^{(i)}+b)+(1-y^{(i)})*cost_2(\\vec w \\cdot \\vec x^{(i)}+b)]}\n",
    "$$\n",
    "令$z=\\vec w \\cdot \\vec x^{(i)}+b$ ，当$y^{(i)} =1$ 时，损失函数为 \n",
    "$$\n",
    "cost_1(z) = max\\{0, -z+1\\}\n",
    "$$\n",
    "当$y^{(i)} =0$ 时，损失函数为\n",
    "$$\n",
    "cost_2(z) = max\\{0, z+1\\}\n",
    "$$\n",
    "这里借助吴恩达课程里对比logistic regression的损失函数的图对这个损失函数进行可视化，其实这种loss好像有一个名字叫hingeloss\n",
    "\n",
    "![image-20221024172509546](https://s2.loli.net/2022/10/24/GUzbt6uYEHTZ3af.png)\n",
    "\n",
    "\n",
    "\n",
    "## 3. SVM witho Regularization \n",
    "\n",
    "给损失函数加入正则化项，这里C为常数，当C比较大时容易过拟合，C比较小时，容易欠拟合bias容易偏大。\n",
    "$$\n",
    "J(w) = C * \\sum_{x_i\\in{M}}{[y^{(i)}*cost_1( \\vec w \\cdot \\vec x^{(i)}+b)+(1-y^{(i)})*cost_2(\\vec w \\cdot \\vec x^{(i)}+b)]} + \\frac{1}{2}*\\sum_{i=1}^n{\\theta_i^2}\n",
    "$$\n",
    "\n",
    "\n",
    "## 4. large margin classifier的理解\n",
    "\n",
    "\n",
    "\n",
    "SVM还有个名字叫large margin classifier，其实我觉得相比较于逻辑回归，和感知机模型对比能更好的理解margin这个概念，可以参考感知机模型里关于损失函数原理的推导部分。回顾一下感知机的模型和损失函数\n",
    "$$\n",
    "z = \\vec w \\cdot \\vec x + b=w_1x_1+w_2x_2+...+w_nx_n+b\\\\\n",
    "y=sign(z)=\n",
    "\\begin{cases}\n",
    "1, z\\geq0\\\\\n",
    "-1, z<0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "J(w) = -\\sum_{x_i\\in{M}}{y^{(i)}( \\vec w \\cdot \\vec x^{(i)}+b)}\n",
    "$$\n",
    "\n",
    "可以看到这里的预测模型是和SVM完全一致的，唯一的区别在于损失函数。另外一个细微的差别是这里的负样本的定义，这里其实我们也可以把感知机模型的损失函数转换为负样本为0的模式，另外我们这里通过cost设置max函数，可以把损失函数从面向误分类点的转为总样本点的损失和，因为对于正确分类的点其cost会等于0.\n",
    "$$\n",
    "J(w) = -\\sum_{x_i\\in{M}}{[y^{(i)}*cost_1( \\vec w \\cdot \\vec x^{(i)}+b)+(1-y^{(i)})*cost_2(\\vec w \\cdot \\vec x^{(i)}+b)]}\n",
    "$$\n",
    "令$z=\\vec w \\cdot \\vec x^{(i)}+b$ ，当$y^{(i)} =1$ 时，损失函数为 \n",
    "$$\n",
    "cost_1(z) =max\\{0, -z\\}\n",
    "$$\n",
    "当$y^{(i)} =0$ 时，损失函数为\n",
    "$$\n",
    "cost_2(z) =max\\{0, z\\}\n",
    "$$\n",
    "因此，我们可以直观的发现，SVM和感知机的区别在于加上1，且取max{0，?}，从感知机里的原理推导我们得知$z=\\vec w \\cdot \\vec x^{(i)}+b$ 的绝对值几何意义其实是分类点到超平面$\\vec x \\vec w + b=0$ 的距离，因此从几何上理解SVM，对于正样本，$cost_1(z) = max\\{0, -z+1\\}$ 我们希望其到超平面$\\vec x \\vec w + b=0$的距离能大于1；对于负样本，$cost_2(z) = max\\{0, z+1\\}$ ，我们希望其到超平面$\\vec x \\vec w + b=0$的距离也能大于1，负样本在超平面另外一侧。总结，从这里可以理解为什么svm又名large margin classifier。因为它的loss要求比感知机强，它希望超平面能留在中间区域。\n",
    "\n",
    "这里可以参考吴恩达课程里的图进一步可视化理解\n",
    "\n",
    "![image-20221024153613493](https://s2.loli.net/2022/10/24/uy1KMYhJtSrVGWm.png)\n",
    "\n",
    "## 5. SVM with Kernel\n",
    "\n",
    "对于非线性边界的问题，svm似乎经常会结合kernel来解决。简单来说加入kernel需要确定两点，一是选择similarity函数K，二是选择landmark，一般就直接选择所有样本点了。最常用的核函数有高斯核函数\n",
    "$$\n",
    "K(x, l) = exp(-\\frac{||x-l||_2^2}{2\\sigma^2})\n",
    "$$\n",
    "因此假设有m个样本点，每个样本点的初始特征维度为n，对每个样本点与另外的m个样本点进行核函数运算，得到m维新特征，因此最后的特征矩阵X为m*m维。\n",
    "\n",
    "## 6. 分类算法的选择经验\n",
    "\n",
    "\n",
    "\n",
    "![image-20221024160721457](https://s2.loli.net/2022/10/24/NI9jWfcugybxCRD.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.sklearn实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "X = np.array([\n",
    "    [1, 1],\n",
    "    [2, 2],\n",
    "    [1, 2],\n",
    "    [2, 3],\n",
    "    [2, 1],\n",
    "    [-1, -1],\n",
    "    [-2, -2],\n",
    "    [-2, -1],\n",
    "    [-1, -2],\n",
    "    [-3, -2],\n",
    "])\n",
    "y = np.array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0], dtype=np.int8)\n",
    "pos_data = X[y==1]\n",
    "neg_data = X[y==0]\n",
    "plt.scatter(pos_data[:, 0], pos_data[:, 1], marker='o', color='b')\n",
    "plt.scatter(neg_data[:, 0], neg_data[:, 1], marker='o', color='r')\n",
    "\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X, y)\n",
    "X_test = np.array([\n",
    "    [2, 2.5],\n",
    "    [-2, -2.5],\n",
    "    [3, 3],\n",
    "    [-3, -3],\n",
    "])\n",
    "y_test = svc.predict(X_test)\n",
    "print(y_test)\n",
    "X_test_pos = X_test[y_test==1]\n",
    "X_test_neg = X_test[y_test==0]\n",
    "plt.scatter(X_test_pos[:, 0], X_test_pos[:, 1], marker='+', color='b')\n",
    "plt.scatter(X_test_neg[:, 0], X_test_neg[:, 1], marker='+', color='r')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('myEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e38ba9a5944a3421f77c1c2862354ade0dcdf22eb57eefe299a6ebec0eb6e7ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
